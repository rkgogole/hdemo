{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#4285f4'>Overview</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook empowers marketers to create hyper-personalized emails with unique marketing text and images generated for each customer. By analyzing current trends in Germany related to Automotive Industry and Car Insurance; and leveraging Gemini's advanced capabilities, we identify relevant trends and tailor messages to customers' interests, even translating content and providing transparent explanations for all AI-generated elements.\n",
    "\n",
    "Process Flow:\n",
    "1. Used GIGA app shown by gTech colleagues to create insights using these 3 keywords: car insurance, insurance coverage, electric vehicles [English language and Germany Location]\n",
    "2. Used Gemini to extract relevant keywords from these Insights \n",
    "3. Generate a marketing message based upon the customer's profile. Determine their current policy and any specifics that would help tailor the message, combine it with keywords and timeliness\n",
    "4. Pass the marketing message and ask Gemini to create a prompt for Imagen3\n",
    "    * a. Gemini will author our Imagen3 prompt for us.\n",
    "5. Generate the image based upon the image prompt Gemini created\n",
    "6. Pass the marketing message, user profile and generated image to Gemini Vision.\n",
    "    * a. Ask Gemini to verify that the image satisfies the original request.\n",
    "7 Ask Gemini to translate the marketing text into another language.\n",
    "    * a. Ask Gemini to verify the translation to make sure it did what we asked\n",
    "8. Create the HTML email message.\n",
    "\n",
    "Notes:\n",
    "* We could also create campaigns based on customer segmentation in place \n",
    "* Combine it with Keyword Insights to create timely campaigns for relevant Audiences\n",
    "\n",
    "Cost:\n",
    "* Very Small: A few calls to Gemini, Imagen3 and BigQuery\n",
    "* Medium: Remember to stop your Colab Enterprise Notebook Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m65vp54BUFRi"
   },
   "source": [
    "### <font color='#4285f4'>Pip installs</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MaWM6H5i6rX"
   },
   "outputs": [],
   "source": [
    "# PIP Installs\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOYsEVSXp6IP"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import HTML\n",
    "import IPython.display\n",
    "import google.auth\n",
    "import requests\n",
    "import json\n",
    "import uuid\n",
    "import base64\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import base64\n",
    "import random\n",
    "\n",
    "import logging\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt, before_sleep_log, retry_if_exception\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google import genai\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add location, storage bucket, project and user details below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMlHl3bnkFPZ"
   },
   "outputs": [],
   "source": [
    "# Set these (run this cell to verify the output)\n",
    "\n",
    "bigquery_location = \"TO_DO_DEVELOPER\"\n",
    "location = \"TO_DO_DEVELOPER\"\n",
    "storage_account = \"TO_DO_DEVELOPER\"\n",
    "project_id = \"TO_DO_DEVELOPER\"\n",
    "dataset_id = \"TO_DO_DEVELOPER\"\n",
    "user = \"TO_DO_DEVELOPER\"\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Format the date and time as desired\n",
    "formatted_date = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "gemini_languages = [\"Arabic (ar)\",  \"Bengali (bn)\",  \"Bulgarian (bg)\",  \"Chinese simplified (zh)\",  \"Chinese traditional (zh)\",\n",
    "  \"Croatian (hr)\",  \"Czech (cs)\",  \"Danish (da)\",  \"Dutch (nl)\",  \"Estonian (et)\",  \"Finnish (fi)\",  \"French (fr)\",\n",
    "  \"German (de)\",  \"Greek (el)\",  \"Hebrew (iw)\",  \"Hindi (hi)\",  \"Hungarian (hu)\",  \"Indonesian (id)\",  \"Italian (it)\",  \"Japanese (ja)\",\n",
    "  \"Korean (ko)\",  \"Latvian (lv)\",  \"Lithuanian (lt)\",  \"Norwegian (no)\",  \"Polish (pl)\",  \"Portuguese (pt)\",  \"Romanian (ro)\",  \"Russian (ru)\",\n",
    "  \"Serbian (sr)\",  \"Slovak (sk)\",  \"Slovenian (sl)\",  \"Spanish (es)\",  \"Swahili (sw)\",  \"Swedish (sv)\",  \"Thai (th)\",  \"Turkish (tr)\",  \"Ukrainian (uk)\",\n",
    "  \"Vietnamese (vi)\"]\n",
    "\n",
    "print(f\"project_id = {project_id}\")\n",
    "print(f\"dataset_id = {dataset_id}\")\n",
    "print(f\"user = {user}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZ6m_wGrK0YG"
   },
   "source": [
    "### <font color='#4285f4'>Helper Methods</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbOjdSP1kN9T"
   },
   "source": [
    "#### restAPIHelper\n",
    "Calls the Google Cloud REST API using the current users credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40wlwnY4kM11"
   },
   "outputs": [],
   "source": [
    "def restAPIHelper(url: str, http_verb: str, request_body: str) -> str:\n",
    "  \"\"\"Calls the Google Cloud REST API passing in the current users credentials\"\"\"\n",
    "\n",
    "  import requests\n",
    "  import google.auth\n",
    "  import json\n",
    "\n",
    "  # Get an access token based upon the current user\n",
    "  creds, project = google.auth.default()\n",
    "  auth_req = google.auth.transport.requests.Request()\n",
    "  creds.refresh(auth_req)\n",
    "  access_token=creds.token\n",
    "\n",
    "  headers = {\n",
    "    \"Content-Type\" : \"application/json\",\n",
    "    \"Authorization\" : \"Bearer \" + access_token\n",
    "  }\n",
    "\n",
    "  if http_verb == \"GET\":\n",
    "    response = requests.get(url, headers=headers)\n",
    "  elif http_verb == \"POST\":\n",
    "    response = requests.post(url, json=request_body, headers=headers)\n",
    "  elif http_verb == \"PUT\":\n",
    "    response = requests.put(url, json=request_body, headers=headers)\n",
    "  elif http_verb == \"PATCH\":\n",
    "    response = requests.patch(url, json=request_body, headers=headers)\n",
    "  elif http_verb == \"DELETE\":\n",
    "    response = requests.delete(url, headers=headers)\n",
    "  else:\n",
    "    raise RuntimeError(f\"Unknown HTTP verb: {http_verb}\")\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    return json.loads(response.content)\n",
    "    #image_data = json.loads(response.content)[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
    "  else:\n",
    "    error = f\"Error restAPIHelper -> ' Status: '{response.status_code}' Text: '{response.text}'\"\n",
    "    raise RuntimeError(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RetryCondition (for retrying LLM calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetryCondition(error):\n",
    "  error_string = str(error)\n",
    "  print(error_string)\n",
    "\n",
    "  retry_errors = [\n",
    "      \"RESOURCE_EXHAUSTED\",\n",
    "      \"No content in candidate\",\n",
    "      # Add more error messages here as needed\n",
    "  ]\n",
    "\n",
    "  for retry_error in retry_errors:\n",
    "    if retry_error in error_string:\n",
    "      print(\"Retrying...\")\n",
    "      return True\n",
    "\n",
    "  return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Q7UAkst0phu"
   },
   "source": [
    "#### Imagen3 Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjHSz0k20sgf"
   },
   "outputs": [],
   "source": [
    "def ImageGen(prompt):\n",
    "  creds, project = google.auth.default()\n",
    "  auth_req = google.auth.transport.requests.Request()\n",
    "  creds.refresh(auth_req)\n",
    "  access_token=creds.token\n",
    "\n",
    "  headers = {\n",
    "      \"Content-Type\" : \"application/json\",\n",
    "      \"Authorization\" : \"Bearer \" + access_token\n",
    "  }\n",
    "\n",
    "  model_version = \"imagen-3.0-generate-001\" # imagen-3.0-fast-generate-001\n",
    "  #model_version = \"imagen-3.0-generate-preview-0611\" # Preview Access Model\n",
    "\n",
    "  # https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/image-generation\n",
    "  # url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project}/locations/{location}/publishers/google/models/imagegeneration:predict\"\n",
    "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project}/locations/{location}/publishers/google/models/{model_version}:predict\"\n",
    "\n",
    "  payload = {\n",
    "    \"instances\": [\n",
    "      {\n",
    "        \"prompt\": prompt\n",
    "      }\n",
    "    ],\n",
    "    \"parameters\": {\n",
    "      \"sampleCount\": 1,\n",
    "      \"personGeneration\" : \"dont_allow\"  # change to allow_adult for people generation\n",
    "    }\n",
    "  }\n",
    "\n",
    "  response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    response_json = json.loads(response.content)\n",
    "    print(f\"Imagen3 response_json: {response_json}\")\n",
    "\n",
    "    if \"blocked\" in response_json:\n",
    "      print(f\"Blocked: {response_json['blocked']}\")\n",
    "\n",
    "    if \"predictions\" in response_json:\n",
    "      image_data = response_json[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
    "      image_data = base64.b64decode(image_data)\n",
    "      filename= str(uuid.uuid4()) + \".png\"\n",
    "      with open(filename, \"wb\") as f:\n",
    "        f.write(image_data)\n",
    "      print(f\"Image generated OK.\")\n",
    "      return filename\n",
    "    else:\n",
    "      raise RuntimeError(f\"No predictions in response: {response.content}\")\n",
    "  else:\n",
    "    error = f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\"\n",
    "    raise RuntimeError(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOFTk6sj1YIV"
   },
   "source": [
    "#### Gemini LLM (Pro 1.0 , Pro 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHit3Hh-1ZAW"
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=1, min=1, max=60), stop=stop_after_attempt(10), retry=retry_if_exception(RetryCondition), before_sleep=before_sleep_log(logging.getLogger(), logging.INFO))\n",
    "def GeminiLLM(prompt, model = \"gemini-1.5-pro-001\", response_schema = None,\n",
    "                 temperature = 1, topP = 1, topK = 32):\n",
    "\n",
    "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
    "  # model = \"gemini-1.5-pro-001\"\n",
    "  # model = \"gemini-pro\" # This does support topK (but the function is more generic)\n",
    "  # model = \"gemini-1.0-pro\" # This does not support response_schema\n",
    "\n",
    "  llm_response = None\n",
    "  if temperature < 0:\n",
    "    temperature = 0\n",
    "\n",
    "  creds, project = google.auth.default()\n",
    "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
    "  creds.refresh(auth_req)\n",
    "  access_token=creds.token\n",
    "\n",
    "  headers = {\n",
    "      \"Content-Type\" : \"application/json\",\n",
    "      \"Authorization\" : \"Bearer \" + access_token\n",
    "  }\n",
    "\n",
    "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
    "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
    "\n",
    "  generation_config = {\n",
    "    \"temperature\": temperature,\n",
    "    \"topP\": topP,\n",
    "    \"maxOutputTokens\": 8192,\n",
    "    \"candidateCount\": 1,\n",
    "    \"responseMimeType\": \"application/json\",\n",
    "  }\n",
    "\n",
    "  # Add inthe response schema for when it is provided\n",
    "  if response_schema is not None:\n",
    "    generation_config[\"responseSchema\"] = response_schema\n",
    "\n",
    "  if model == \"gemini-pro\" or model == \"gemini-1.0-pro\" or model == \"gemini-1.0-pro-vision-001\":\n",
    "    generation_config[\"topK\"] = topK\n",
    "\n",
    "  payload = {\n",
    "    \"contents\": {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": {\n",
    "          \"text\": prompt\n",
    "      },\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      **generation_config\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }\n",
    "\n",
    "  response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    try:\n",
    "      json_response = json.loads(response.content)\n",
    "    except Exception as error:\n",
    "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
    "\n",
    "    if \"candidates\" in json_response:\n",
    "      candidates = json_response[\"candidates\"]\n",
    "      if len(candidates) > 0:\n",
    "        candidate = candidates[0]\n",
    "        if \"content\" in candidate:\n",
    "          content = candidate[\"content\"]\n",
    "          if \"parts\" in content:\n",
    "            parts = content[\"parts\"]\n",
    "            if len(parts):\n",
    "              part = parts[0]\n",
    "              if \"text\" in part:\n",
    "                text = part[\"text\"]\n",
    "                llm_response = text\n",
    "              else:\n",
    "                raise RuntimeError(\"No text in part: {response.content}\")\n",
    "            else:\n",
    "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
    "          else:\n",
    "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
    "        else:\n",
    "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
    "      else:\n",
    "        raise RuntimeError(\"No candidates: {response.content}\")\n",
    "    else:\n",
    "      raise RuntimeError(\"No candidates: {response.content}\")\n",
    "\n",
    "    # Remove some typically response characters (if asking for a JSON reply)\n",
    "    llm_response = llm_response.replace(\"```json\",\"\")\n",
    "    llm_response = llm_response.replace(\"```\",\"\")\n",
    "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
    "\n",
    "    return llm_response\n",
    "\n",
    "  else:\n",
    "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rWXSCd5VCPjf"
   },
   "outputs": [],
   "source": [
    "@retry(wait=wait_exponential(multiplier=1, min=1, max=60), stop=stop_after_attempt(10), retry=retry_if_exception(RetryCondition), before_sleep=before_sleep_log(logging.getLogger(), logging.INFO))\n",
    "def GeminiLLM_VerifyImage(prompt, imageBase64, model = \"gemini-1.5-pro-001\", response_schema = None,\n",
    "                 temperature = 1, topP = 1, topK = 32):\n",
    "\n",
    "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
    "  # model = \"gemini-1.5-pro-001\"\n",
    "  # model = \"gemini-pro\" # This does support topK (but the function is more generic)\n",
    "  # model = \"gemini-1.0-pro\" # This does not support response_schema\n",
    "\n",
    "  llm_response = None\n",
    "  if temperature < 0:\n",
    "    temperature = 0\n",
    "\n",
    "  creds, project = google.auth.default()\n",
    "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
    "  creds.refresh(auth_req)\n",
    "  access_token=creds.token\n",
    "\n",
    "  headers = {\n",
    "      \"Content-Type\" : \"application/json\",\n",
    "      \"Authorization\" : \"Bearer \" + access_token\n",
    "  }\n",
    "\n",
    "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
    "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
    "\n",
    "  generation_config = {\n",
    "    \"temperature\": temperature,\n",
    "    \"topP\": topP,\n",
    "    \"maxOutputTokens\": 8192,\n",
    "    \"candidateCount\": 1,\n",
    "    \"responseMimeType\": \"application/json\",\n",
    "  }\n",
    "\n",
    "  # Add inthe response schema for when it is provided\n",
    "  if response_schema is not None:\n",
    "    generation_config[\"responseSchema\"] = response_schema\n",
    "\n",
    "  if model == \"gemini-pro\" or model == \"gemini-1.0-pro\" or model == \"gemini-1.0-pro-vision-001\":\n",
    "    generation_config[\"topK\"] = topK\n",
    "\n",
    "  payload = {\n",
    "    \"contents\": {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": [\n",
    "          { \"text\": prompt },\n",
    "          { \"inlineData\": {  \"mimeType\": \"image/png\", \"data\": f\"{imageBase64}\" } }\n",
    "        ]\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      **generation_config\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }\n",
    "\n",
    "  response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "    try:\n",
    "      json_response = json.loads(response.content)\n",
    "    except Exception as error:\n",
    "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
    "\n",
    "    if \"candidates\" in json_response:\n",
    "      candidates = json_response[\"candidates\"]\n",
    "      if len(candidates) > 0:\n",
    "        candidate = candidates[0]\n",
    "        if \"content\" in candidate:\n",
    "          content = candidate[\"content\"]\n",
    "          if \"parts\" in content:\n",
    "            parts = content[\"parts\"]\n",
    "            if len(parts):\n",
    "              part = parts[0]\n",
    "              if \"text\" in part:\n",
    "                text = part[\"text\"]\n",
    "                llm_response = text\n",
    "              else:\n",
    "                raise RuntimeError(\"No text in part: {response.content}\")\n",
    "            else:\n",
    "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
    "          else:\n",
    "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
    "        else:\n",
    "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
    "      else:\n",
    "        raise RuntimeError(\"No candidates: {response.content}\")\n",
    "    else:\n",
    "      raise RuntimeError(\"No candidates: {response.content}\")\n",
    "\n",
    "    # Remove some typically response characters (if asking for a JSON reply)\n",
    "    llm_response = llm_response.replace(\"```json\",\"\")\n",
    "    llm_response = llm_response.replace(\"```\",\"\")\n",
    "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
    "\n",
    "    return llm_response\n",
    "\n",
    "  else:\n",
    "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bI-KJELZ1jgt"
   },
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmnCwYvA1kZv"
   },
   "outputs": [],
   "source": [
    "def RunQuery(sql):\n",
    "  import time\n",
    "  from google.cloud import bigquery\n",
    "  client = bigquery.Client()\n",
    "\n",
    "  if (sql.startswith(\"SELECT\") or sql.startswith(\"WITH\")):\n",
    "      df_result = client.query(sql).to_dataframe()\n",
    "      return df_result\n",
    "  else:\n",
    "    job_config = bigquery.QueryJobConfig(priority=bigquery.QueryPriority.INTERACTIVE)\n",
    "    query_job = client.query(sql, job_config=job_config)\n",
    "\n",
    "    # Check on the progress by getting the job's updated state.\n",
    "    query_job = client.get_job(\n",
    "        query_job.job_id, location=query_job.location\n",
    "    )\n",
    "    print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
    "\n",
    "    while query_job.state != \"DONE\":\n",
    "      time.sleep(2)\n",
    "      query_job = client.get_job(\n",
    "          query_job.job_id, location=query_job.location\n",
    "          )\n",
    "      print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
    "\n",
    "    if query_job.error_result == None:\n",
    "      return True\n",
    "    else:\n",
    "      raise Exception(query_job.error_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_OAO_-LC1k3m"
   },
   "outputs": [],
   "source": [
    "def convert_png_to_base64(image_path):\n",
    "  image = cv2.imread(image_path)\n",
    "\n",
    "  # Convert the image to a base64 string.\n",
    "  _, buffer = cv2.imencode('.png', image)\n",
    "  base64_string = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "  return base64_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNAmwvAf1knl"
   },
   "outputs": [],
   "source": [
    "def PrettyPrintJson(json_string):\n",
    "  json_object = json.loads(json_string)\n",
    "  json_formatted_str = json.dumps(json_object, indent=2)\n",
    "  return json_formatted_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBH7sIg3XlGv"
   },
   "outputs": [],
   "source": [
    "def GetNextPrimaryKey(fully_qualified_table_name, field_name):\n",
    "  from google.cloud import bigquery\n",
    "  client = bigquery.Client()\n",
    "  sql = f\"\"\"\n",
    "  SELECT IFNULL(MAX({field_name}),0) AS result\n",
    "    FROM `{fully_qualified_table_name}`\n",
    "  \"\"\"\n",
    "  # print(sql)\n",
    "  df_result = client.query(sql).to_dataframe()\n",
    "  # display(df_result)\n",
    "  return df_result['result'].iloc[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BljTy6yYaIp5"
   },
   "outputs": [],
   "source": [
    "# This was generated by GenAI\n",
    "\n",
    "def copy_file_to_gcs(local_file_path, bucket_name, destination_blob_name):\n",
    "  \"\"\"Copies a file from a local drive to a GCS bucket.\n",
    "\n",
    "  Args:\n",
    "      local_file_path: The full path to the local file.\n",
    "      bucket_name: The name of the GCS bucket to upload to.\n",
    "      destination_blob_name: The desired name of the uploaded file in the bucket.\n",
    "\n",
    "  Returns:\n",
    "      None\n",
    "  \"\"\"\n",
    "\n",
    "  import os\n",
    "  from google.cloud import storage\n",
    "\n",
    "  # Ensure the file exists locally\n",
    "  if not os.path.exists(local_file_path):\n",
    "      raise FileNotFoundError(f\"Local file '{local_file_path}' not found.\")\n",
    "\n",
    "  # Create a storage client\n",
    "  storage_client = storage.Client()\n",
    "\n",
    "  # Get a reference to the bucket\n",
    "  bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "  # Create a blob object with the desired destination path\n",
    "  blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "  # Upload the file from the local filesystem\n",
    "  content_type = \"\"\n",
    "  if local_file_path.endswith(\".html\"):\n",
    "    content_type = \"text/html; charset=utf-8\"\n",
    "\n",
    "  if local_file_path.endswith(\".json\"):\n",
    "    content_type = \"application/json; charset=utf-8\"\n",
    "\n",
    "  if content_type == \"\":\n",
    "    blob.upload_from_filename(local_file_path)\n",
    "  else:\n",
    "    blob.upload_from_filename(local_file_path, content_type = content_type)\n",
    "\n",
    "  print(f\"File '{local_file_path}' uploaded to GCS bucket '{bucket_name}' as '{destination_blob_name}.  Content-Type: {content_type}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYRHDPdVKBzd"
   },
   "source": [
    "### <font color='#4285f4'>Create BigQuery Tables</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJsTtUbD5SsQ"
   },
   "outputs": [],
   "source": [
    "customer_hyper_personalised_email_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS `{dataset_id}.customer_hyper_personalised_email`\n",
    "(\n",
    "    customer_id                                    STRING  NOT NULL OPTIONS(description=\"Primary key.\"),\n",
    "    email_date                                     DATE    NOT NULL OPTIONS(description=\"The date of the email.\"),\n",
    "\n",
    "    llm_marketing_prompt                           STRING  OPTIONS(description=\"The prompt to generate the marketing email text.\"),\n",
    "    llm_marketing_prompt_response_json             JSON    OPTIONS(description=\"The response from the llm marketing prompt in json.\"),\n",
    "    llm_marketing_prompt_response_text             STRING  OPTIONS(description=\"The response from the llm marketing prompt in text.\"),\n",
    "\n",
    "    llm_orginial_image_prompt                      STRING  OPTIONS(description=\"The prompt to generate the original image text.\"),\n",
    "    llm_orginial_image_prompt_response_json        JSON    OPTIONS(description=\"The response from the llm original prompt in json.\"),\n",
    "    llm_orginial_image_prompt_response_text        STRING  OPTIONS(description=\"The response from the llm original prompt in text.\"),\n",
    "\n",
    "    llm_improved_image_prompt                      STRING  OPTIONS(description=\"The prompt to generate the improved image text.\"),\n",
    "    -- The improved prompt will be passed to Imagen3\n",
    "    --llm_improved_image_prompt_response_json      JSON    OPTIONS(description=\"The response from the llm improved prompt in json.\"),\n",
    "    --llm_improved_image_prompt_response_text      STRING  OPTIONS(description=\"The response from the llm improved prompt in text.\"),\n",
    "\n",
    "    llm_verify_image_prompt                        STRING  OPTIONS(description=\"The prompt to verify the generated image.\"),\n",
    "    llm_verify_image_response_json                 JSON    OPTIONS(description=\"The response from verify the generated image in json.\"),\n",
    "    llm_verify_image_text                          STRING  OPTIONS(description=\"The response from verify the generated image in text.\"),\n",
    "\n",
    "    llm_translation_language_prompt                STRING  OPTIONS(description=\"The prompt to generate the secondary lanagage text.\"),\n",
    "    llm_translation_language_prompt_response_json  JSON    OPTIONS(description=\"The response from the llm secondary lanagage prompt in json.\"),\n",
    "    llm_translation_language_prompt_response_text  STRING  OPTIONS(description=\"The response from the llm secondary lanagage prompt in text.\"),\n",
    "\n",
    "    llm_validate_translation_prompt                STRING  OPTIONS(description=\"The prompt to generate the vadiation of the translation text.\"),\n",
    "    llm_validate_translation_prompt_response_json  JSON    OPTIONS(description=\"The response from the llm vadiation of the translation prompt in json.\"),\n",
    "    llm_validate_translation_prompt_response_text  STRING  OPTIONS(description=\"The response from the llm vadiation of the translation prompt in text.\"),\n",
    "\n",
    "    image_gcs_filename                             STRING  OPTIONS(description=\"The GCS path for the marketing campaign image.\"),\n",
    "    image_http_url                                 STRING  OPTIONS(description=\"The HTTP path for the marketing campaign image.\"),\n",
    "    image_generated                                BOOLEAN OPTIONS(description=\"Has the image been generated and saved to GCS.\"),\n",
    "    image_verified                                 BOOLEAN OPTIONS(description=\"Did the image pass verification.\"),\n",
    "\n",
    "    html_gcs_filename                              STRING  OPTIONS(description=\"The GCS path for the marketing campaign HTML file.\"),\n",
    "    html_http_url                                  STRING  OPTIONS(description=\"The HTTP path for the marketing campaign HTML file.\"),\n",
    "    html_generated                                 BOOLEAN OPTIONS(description=\"Has the HTML been generated and saved to GCS.\"),\n",
    "    translation_verified                           BOOLEAN OPTIONS(description=\"Did the translation pass verification.\"),\n",
    ")\n",
    "CLUSTER BY customer_id;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = bigquery.Client()\n",
    "client.query_and_wait(customer_hyper_personalised_email_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#4285f4'>GIGA app presented by gTech team is used here to check the Trends and Insights for Car Insurance; and Gemini is used to extract keywords from those to be used for hypersonalised assets creation:</font> \n",
    "\n",
    "Decoding Car Insurance, Electric Vehicle, and Insurance Coverage Search Trends: Insights for Marketing & Strategy\n",
    "This analysis examines the provided Google Ads keywords related to car insurance, electric vehicles, and general insurance coverage, sorted by descending YoY growth rate, to uncover consumer trends and potential marketing opportunities.\n",
    "\n",
    "Overall Trends:\n",
    "Explosive Growth in Specific Insurance Needs: Several keywords related to specific insurance needs, such as \"liability insurance only\" and \"best car and home insurance\", show extremely high growth. This suggests consumers are actively seeking very specific coverage options and are comparison shopping.\n",
    "Strong Interest in Affordable Options: Keywords related to affordability, such as \"most affordable car insurance\" and \"cheap medical insurance\" are experiencing significant growth, indicating a strong consumer focus on cost-effectiveness.\n",
    "Growing Demand for Medical Insurance: Several medical insurance related keywords are experiencing high growth, such as \"medical insurance for low income\" and \"medical insurance benefits\".\n",
    "Continued Interest in Electric Vehicles: While not as explosive as some insurance-related terms, there's consistent growth in searches related to electric vehicles (EVs), including specific models and charging solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c51M89g0Ejmz"
   },
   "source": [
    "### <font color='#4285f4'>Use Gemini to extract the Trends Keywords and use them further in hyper personalized assets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from string import punctuation\n",
    "\n",
    "# Download required NLTK data (run once)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('averaged_perceptron_tagger')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt_tab')\n",
    "    nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text, method='basic', num_keywords=10):\n",
    "    \"\"\"\n",
    "    Extract keywords from text using different methods\n",
    "    \n",
    "    Parameters:\n",
    "    - text: input text\n",
    "    - method: 'basic', 'pos', or 'phrases'\n",
    "    - num_keywords: number of keywords to return\n",
    "    \n",
    "    Returns:\n",
    "    - list of keywords\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to lowercase and tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and word not in punctuation]\n",
    "    \n",
    "    if method == 'basic':\n",
    "        # Simple frequency-based approach\n",
    "        word_freq = Counter(tokens)\n",
    "        keywords = [word for word, _ in word_freq.most_common(num_keywords)]\n",
    "        \n",
    "    elif method == 'pos':\n",
    "        # Parts of speech based approach (focus on nouns and adjectives)\n",
    "        tagged = pos_tag(tokens)\n",
    "        important_words = [word for word, tag in tagged if tag.startswith(('NN', 'JJ'))]\n",
    "        word_freq = Counter(important_words)\n",
    "        keywords = [word for word, _ in word_freq.most_common(num_keywords)]\n",
    "        \n",
    "    elif method == 'phrases':\n",
    "        # Extract meaningful phrases (bigrams)\n",
    "        bigrams = nltk.bigrams(tokens)\n",
    "        bigram_freq = Counter(bigrams)\n",
    "        keywords = [f\"{w1} {w2}\" for (w1, w2), _ in bigram_freq.most_common(num_keywords)]\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your trends text\n",
    "trends_text = \"\"\"\n",
    "Specific insurance needs, such as liability insurance only and best car and home insurance. This suggests consumers are actively seeking very specific coverage options and are comparison shopping.\n",
    "Strong Interest in Affordable Options such as most affordable car insurance and cheap medical insurance, indicating a strong consumer focus on cost-effectiveness.\n",
    "Growing Demand for Medical Insurance particularly medical insurance for low income and medical insurance benefits.\n",
    "There's consistent growth in searches related to electric vehicles (EVs), including specific models and charging solutions.\n",
    "\"\"\"\n",
    "\n",
    "# Extract keywords (choose the method that works best for your needs)\n",
    "keywords = extract_keywords(trends_text, method='phrases', num_keywords=15)\n",
    "\n",
    "# Format for prompts\n",
    "prompt_keywords = \", \".join(keywords)\n",
    "\n",
    "# Use in your prompt\n",
    "prompt = f\"Use these keywords to create a marketing message where applicable: {prompt_keywords}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2olP2ZnglJlr"
   },
   "source": [
    "### <font color='#4285f4'>Natural Language search to find the customers for which we want to create hyper personalised emails</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USER_QUERY = \"young driver with a Standard coverage high-value customer, but with low engagement with digital channels\"\n",
    "sql = f\"\"\"\n",
    "WITH customer_ids AS (\n",
    "SELECT\n",
    "  distance,\n",
    "  base.customer_id,\n",
    "FROM VECTOR_SEARCH(\n",
    "  -- base table or subquery\n",
    "  (\n",
    "    SELECT * FROM `{dataset_id}.customer_description_embeddings`\n",
    "  ),\n",
    "\n",
    "  -- embedding column to search in base table - must be of type ARRAY\n",
    "  'customer_description_embedding',\n",
    "\n",
    "  -- query table or subquery - this is where you generate the search embedding\n",
    "  (\n",
    "    SELECT ml_generate_embedding_result, content AS query\n",
    "    FROM ML.GENERATE_EMBEDDING(\n",
    "      MODEL `{dataset_id}.google-textembedding`,\n",
    "        (\n",
    "          -- Search term\n",
    "          SELECT \"{USER_QUERY}\" AS content\n",
    "        ),\n",
    "        STRUCT(\n",
    "          TRUE AS flatten_json_output,\n",
    "          'SEMANTIC_SIMILARITY' as task_type,\n",
    "          768 AS output_dimensionality\n",
    "        )\n",
    "    )\n",
    "  ),\n",
    "  top_k => 10,\n",
    "  distance_type => 'COSINE'\n",
    "))\n",
    "SELECT c.customer_id,first_name,d.customer_description \n",
    "FROM `{dataset_id}.customers` c\n",
    "JOIN `{dataset_id}.policies` p\n",
    "ON  c.customer_id = p.customer_id\n",
    "LEFT JOIN `{dataset_id}.customer_descriptions` d\n",
    "ON c.customer_id = d.customer_id\n",
    "WHERE c.customer_id IN (SELECT customer_id FROM customer_ids)\n",
    "\"\"\"\n",
    "\n",
    "client = bigquery.Client()\n",
    "customers = client.query_and_wait(sql).to_dataframe()\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9eObGGQlMZw"
   },
   "outputs": [],
   "source": [
    "customer_list = []\n",
    "for row in customers.itertuples():\n",
    "  customer_dict = {\n",
    "    \"customer_id\" : row.customer_id,\n",
    "    \"customer_name\" : row.first_name,\n",
    "    \"customer_description\" : row.customer_description\n",
    "  }\n",
    "  print(f\"Customer: {customer_dict}\")\n",
    "  customer_list.append(customer_dict)\n",
    "\n",
    "# Just the Ids so we can query\n",
    "customer_id_list = ([customer['customer_id'] for customer in customer_list])\n",
    "customer_id_list_str = (', '.join(map(str, customer_id_list)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqCpfi1P9KtL"
   },
   "source": [
    "### <font color='#4285f4'>Generate and run the LLM Marketing Prompt</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzZdNARrKHQZ"
   },
   "outputs": [],
   "source": [
    "# In case you re-run (placeholder for delete)\n",
    "\n",
    "##sql = f\"\"\"DELETE\n",
    "           ## FROM `{dataset_id}.customer_hyper_personalised_email`\n",
    "           ##WHERE customer_id IN ('{customer_id_list_str}')\n",
    "           ##AND email_date = CURRENT_DATE();\"\"\"\n",
    "\n",
    "##RunQuery(sql)*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mx8rLbqJ95d0"
   },
   "outputs": [],
   "source": [
    "# For each customer, generate the marketing prompt and run against Gemini\n",
    "\n",
    "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
    "# Make all fields required.\n",
    "#  {\n",
    "#    \"customer_id\" : 0,\n",
    "#    \"email_subject\" : \"text\",\n",
    "#    \"marketing_text\" : \"text\",\n",
    "#    \"explanation\" : \"text\"\n",
    "#  }\n",
    "response_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"required\": [\n",
    "    \"customer_id\",\n",
    "    \"email_subject\",\n",
    "    \"marketing_text\",\n",
    "    \"explanation\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"customer_id\": {\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    \"email_subject\": {\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    \"marketing_text\": {\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    \"explanation\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "for item in customer_list:\n",
    "  print(f\"Customer id: {item['customer_id']}\")\n",
    "  retry = 0\n",
    "  success = False\n",
    "  while not success:\n",
    "    try:\n",
    "      prompt = f\"\"\"You are an experienced insurance marketing analyst specializing in customer personalised reachout at Allianz Insurance, a Germany-based automobile insurance company. \n",
    "        Your task is to craft a highly personalized email for customer {item['customer_name']}\n",
    "        Leverage the following customer data:\n",
    "        Customer id: {item['customer_id']}\n",
    "        Customer Description: {item['customer_description']}\n",
    "        Context: Create a reach out email to this customer to engage with them effectively and suggest product upgrades based on their description.\n",
    "        Goal: Create a persuasive email that encourages the customer to visit Allianz website and upgrade their insurance. Use the same customer id as input\n",
    "        Format: Please provide a complete, ready-to-send email, tailored to the specific customer and next steps. Avoid using placeholders or templates.\n",
    "        Additional keywords: {prompt_keywords}\n",
    "      \"\"\"\n",
    "\n",
    "      print(prompt)\n",
    "      llm_result = GeminiLLM(prompt,response_schema=response_schema)\n",
    "      print(llm_result)\n",
    "      json_result = json.loads(llm_result)\n",
    "      result_escaped_quotes = llm_result.replace(\"\\\\\",\"\\\\\\\\\").replace(\"'\",\"\\'\")\n",
    "      #json_text = json_result['marketing_text'].replace(\"'\",\"\\'\")\n",
    "\n",
    "      # Save to database\n",
    "      try:\n",
    "\n",
    "        sql=f\"\"\"INSERT INTO `{dataset_id}.customer_hyper_personalised_email`\n",
    "                            (customer_id, email_date, llm_marketing_prompt, llm_marketing_prompt_response_json, llm_marketing_prompt_response_text)\n",
    "                    VALUES ('{item['customer_id']}', CURRENT_DATE(), \\\"\\\"\\\"{prompt}\\\"\\\"\\\", JSON\\\"\\\"\\\"{result_escaped_quotes}\\\"\\\"\\\",\\\"\\\"\\\"{json_result['marketing_text']}\\\"\\\"\\\")\"\"\"\n",
    "        #print(sql)\n",
    "        RunQuery(sql)\n",
    "\n",
    "        # Jump out of loop\n",
    "        item['marketing_text'] = json_result['marketing_text']\n",
    "        item['email_subject'] = json_result['email_subject']\n",
    "        success = True\n",
    "\n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "        print(f\"LLM Marketing Prompt [Success] for Customer {item['customer_id']}\")\n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "      except Exception as e:\n",
    "        retry += 1\n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "        print(f\"LLM Marketing Prompt [SQL Error] for Customer {item['customer_id']}: {sql}\")\n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "    except Exception as e:\n",
    "      retry += 1\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "      print(f\"LLM Marketing Prompt [Error] for Customer {item['customer_id']}: {e}\")\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "    if retry > 5:\n",
    "      print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "      print(f\"LLM Marketing Prompt [Retry Limit Reached - Skipping] for Customer {item['customer_id']}\")\n",
    "      print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "      break # Skip this customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of customers:\", len(customer_list))\n",
    "print(\"Customer list contents:\", customer_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#4285f4'>Create an image prompt and enhance it by running it through Gemini</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each customer, generate an improved image prompt using Gemini\n",
    "\n",
    "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
    "# Make all fields required.\n",
    "#  {\n",
    "#    \"customer_id\" : 0,\n",
    "#    \"image_prompt\" : \"text\"\n",
    "#    \"explanation\" : \"text\"\n",
    "#  }\n",
    "response_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"required\": [\n",
    "    \"customer_id\",\n",
    "    \"image_prompt\",\n",
    "    \"explanation\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"customer_id\": {\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    \"image_prompt\": {\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    \"explanation\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "for item in customer_list:\n",
    "  print(f\"Customer id: {item['customer_id']}\")\n",
    "  retry = 0\n",
    "  success = False\n",
    "  while not success:\n",
    "    try:\n",
    "      prompt = f\"\"\"You are a marketing expert at Allianz Insurance, a Germany-based automobile insurance company, your task is to craft a highly personalized image.\n",
    "      You need to send out a hyper-personalized email to a customer {item['customer_name']}\n",
    "      Generate a LLM Prompt to generate a marketing image based upon the customer's profile and the marketing message we are sending in the email.\n",
    "      Do not show any damaged cars or damaged objects.\n",
    "      The image can include their current car and any relevant objects as per personalized email text.\n",
    "      We want the image to be specific to this customer and their car insurance.\n",
    "      Think creatively and use the customer's interests to create a unique image.\n",
    "      Make sure you state the image should be photo realistic.\n",
    "      Avoid and copyrighted names or objects such as sporting teams names.\n",
    "      Avoid mentioning any celebrity names or specific people.\n",
    "      Do not include references to kids or children in the image prompt.\n",
    "      Only audits can be rendered by the image process.\n",
    "      This this through step by step.\n",
    "      Double check for kids, children, or copyrighted sports teams names.\n",
    "\n",
    "      Customer's profile:\n",
    "        Customer id: {item['customer_id']}\n",
    "        Customer Name: {item['customer_name']}\n",
    "        Customer Description: {item['customer_description']}\n",
    "\n",
    "      Marketing Message: {item['marketing_text']}\n",
    "        \"\"\"\n",
    "\n",
    "      print(prompt)\n",
    "      llm_result = GeminiLLM(prompt,response_schema=response_schema)\n",
    "      print(llm_result)\n",
    "      json_result = json.loads(llm_result)\n",
    "      result_escaped_quotes = llm_result.replace(\"\\\\\",\"\\\\\\\\\").replace(\"'\",\"\\'\")\n",
    "\n",
    "      # Save to database\n",
    "      try:\n",
    "        sql=f\"\"\"UPDATE `{dataset_id}.customer_hyper_personalised_email`\n",
    "                   SET llm_orginial_image_prompt = \\\"\\\"\\\"{prompt}\\\"\\\"\\\",\n",
    "                       llm_orginial_image_prompt_response_json = JSON\\\"\\\"\\\"{result_escaped_quotes}\\\"\\\"\\\",\n",
    "                       llm_orginial_image_prompt_response_text = \\\"\\\"\\\"{json_result['image_prompt']}\\\"\\\"\\\",\n",
    "                       llm_improved_image_prompt = \\\"\\\"\\\"{json_result['image_prompt']}\\\"\\\"\\\"\n",
    "                 WHERE customer_id = '{item['customer_id']}'\"\"\"\n",
    "\n",
    "        #print(sql)\n",
    "        RunQuery(sql)\n",
    "\n",
    "        # Jump out of loop\n",
    "        item['image_prompt'] = json_result['image_prompt']\n",
    "        item['image_explanation'] = json_result['explanation']\n",
    "        success = True\n",
    "\n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "        print(f\"LLM Image Prompt [Success] for Customer {item['customer_id']}\")\n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "      except Exception as e:\n",
    "        retry += 1\n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "        print(f\"LLM Image Prompt [SQL Error] for Customer {item['customer_id']}: {sql}\")\n",
    "        print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "    except Exception as e:\n",
    "      retry += 1\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "      print(f\"LLM Image Prompt [Error] for Customer {item['customer_id']}: {e}\")\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "    if retry > 5:\n",
    "      print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "      print(f\"LLM Image Prompt [Retry Limit Reached - Skipping] for Customer {item['customer_id']}\")\n",
    "      print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "      break # Skip this customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_ids = customer_id_list_str.split(', ')  # Split into individual IDs\n",
    "customer_ids_formatted = \"'\" + \"', '\".join(customer_ids) + \"'\"  # Format each ID with quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Results\n",
    "sql=f\"\"\"SELECT customer_id, llm_orginial_image_prompt, llm_orginial_image_prompt_response_json, llm_improved_image_prompt\n",
    "          FROM `{dataset_id}.customer_hyper_personalised_email`\n",
    "         WHERE customer_id IN ({customer_ids_formatted})\n",
    "           AND email_date = CURRENT_DATE()\"\"\"\n",
    "\n",
    "print(sql)\n",
    "df_process = RunQuery(sql)\n",
    "df_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0o5gCL_AWqBQ"
   },
   "source": [
    "### <font color='#4285f4'>Call Imagen3 with the updated prompt</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGgdgKdwWqBQ"
   },
   "outputs": [],
   "source": [
    "# For each customer, generate the image using Imagen3\n",
    "for item in customer_list:\n",
    "  print(f\"Customer id: {item['customer_id']}\")\n",
    "  try:\n",
    "    image_prompt = item['image_prompt']\n",
    "    print(f\"Image Prompt: {image_prompt}\")\n",
    "    print(f\"Image Prompt Explanation: {item['image_explanation']}\")\n",
    "    filename = ImageGen(item['image_prompt'])\n",
    "\n",
    "    img = Image.open(filename)\n",
    "    img.thumbnail([500,500]) # width, height\n",
    "    IPython.display.display(img)\n",
    "\n",
    "    # Save image to GCS\n",
    "    dest_filename = f\"email_campaign_{item['customer_id']}.png\"\n",
    "    copy_file_to_gcs(filename, storage_account, f\"insurance-data/Campaign-Assets-Hyper-Personalised-Email/email-{formatted_date}/{dest_filename}\")\n",
    "    item['gcs_filename'] = f\"gs://{storage_account}/insurance-data/Campaign-Assets-Hyper-Personalised-Email/email-{formatted_date}/{dest_filename}\"\n",
    "    item['html_filename'] = f\"https://storage.cloud.google.com/{storage_account}/insurance-data/Campaign-Assets-Hyper-Personalised-Email/email-{formatted_date}/{dest_filename}\"\n",
    "\n",
    "    # Update table in BigQuery\n",
    "    try:\n",
    "      sql=f\"\"\"UPDATE `{dataset_id}.customer_hyper_personalised_email`\n",
    "                  SET image_gcs_filename = '{item['gcs_filename']}',\n",
    "                      image_http_url = '{item['html_filename']}',\n",
    "                      image_generated = TRUE\n",
    "                WHERE customer_id = '{item['customer_id']}'\"\"\"\n",
    "\n",
    "      #print(sql)\n",
    "      RunQuery(sql)\n",
    "      item['image_filename'] = filename\n",
    "\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "      print(f\"Imagen3 [Success] for Customer {item['customer_id']}\")\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "    except Exception as e:\n",
    "      retry += 1\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "      print(f\"Imagen3 [SQL Error] for Customer {item['customer_id']}: {sql}\")\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n",
    "    print(f\"Imagen3 [Error] for Customer {item['customer_id']}: {e}\")\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmJEbPmWO7PE"
   },
   "outputs": [],
   "source": [
    "# To view the bucket\n",
    "print(f\"https://console.cloud.google.com/storage/browser/{storage_account}/insurance-data/Campaign-Assets-Hyper-Personalised-Email/email-{formatted_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGhMT7ohDPcI"
   },
   "outputs": [],
   "source": [
    "# View Results\n",
    "sql=f\"\"\"SELECT customer_id, image_gcs_filename, image_http_url, image_generated\n",
    "          FROM `{dataset_id}.customer_hyper_personalised_email`\n",
    "         WHERE customer_id IN ({customer_ids_formatted})\n",
    "           AND email_date = CURRENT_DATE()\"\"\"\n",
    "\n",
    "print(sql)\n",
    "df_process = RunQuery(sql)\n",
    "df_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfwG_ykdCypl"
   },
   "source": [
    "### <font color='#4285f4'>Verify the Generated Image with Gemini Vision</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-_J7-7Y-S5W"
   },
   "outputs": [],
   "source": [
    "# Verify the generate image is correct\n",
    "\n",
    "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
    "# Make all fields required.\n",
    "#  {\n",
    "#    \"image_verified\" : true\n",
    "#    \"explanation\" : \"text\"\n",
    "#  }\n",
    "response_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"required\": [\n",
    "    \"image_verified\",\n",
    "    \"explanation\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"image_verified\": {\n",
    "      \"type\": \"boolean\"\n",
    "    },\n",
    "    \"explanation\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "json_schema = '{ \"image_verified\" : true, \"explanation\" : \"text\" }'\n",
    "\n",
    "for item in customer_list:\n",
    "  print(f\"Customer id: {item['customer_id']}\")\n",
    "  try:\n",
    "    image_prompt = item['image_prompt']\n",
    "    print(f\"Image Prompt: {image_prompt}\")\n",
    "    print(f\"Image Prompt Explanation: {item['image_explanation']}\")\n",
    "    filename = item['image_filename']\n",
    "\n",
    "    prompt = f\"\"\"I need you to verify that the below image meets the following criteria:\n",
    "    <ImagePrompt>\n",
    "    {item['image_prompt']}\n",
    "    </ImagePrompt>\n",
    "    <ImageExplanation>\n",
    "    {item['image_explanation']}\n",
    "    </ImageExplanation>\n",
    "    \"\"\"\n",
    "\n",
    "    print(prompt)\n",
    "    imageBase64 = convert_png_to_base64(filename)\n",
    "    llm_result = GeminiLLM_VerifyImage(prompt, imageBase64, response_schema=response_schema)\n",
    "    print(llm_result)\n",
    "    json_result = json.loads(llm_result)\n",
    "    result_escaped_quotes = llm_result.replace(\"\\\\\",\"\\\\\\\\\").replace(\"'\",\"\\'\")\n",
    "\n",
    "\n",
    "    # Update table in BigQuery\n",
    "    try:\n",
    "      sql=f\"\"\"UPDATE `{dataset_id}.customer_hyper_personalised_email`\n",
    "                  SET llm_verify_image_prompt = \\\"\\\"\\\"{prompt}\\\"\\\"\\\",\n",
    "                      llm_verify_image_response_json = JSON\\\"\\\"\\\"{result_escaped_quotes}\\\"\\\"\\\",\n",
    "                      llm_verify_image_text = \\\"\\\"\\\"{json_result['explanation']}\\\"\\\"\\\",\n",
    "                      image_verified = {json_result['image_verified']}\n",
    "                WHERE customer_id = '{item['customer_id']}'\"\"\"\n",
    "\n",
    "      #print(sql)\n",
    "      RunQuery(sql)\n",
    "\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "      print(f\"Imagen3 Verification [Success] for Customer {item['customer_id']}\")\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "    except Exception as e:\n",
    "      retry += 1\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "      print(f\"Imagen3 Verification [SQL Error] for Customer {item['customer_id']}: {sql}\")\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n",
    "    print(f\"Imagen3 Verification [Error] for Customer {item['customer_id']}: {e}\")\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0H1cwl2CJdj"
   },
   "outputs": [],
   "source": [
    "# View Results\n",
    "sql=f\"\"\"SELECT customer_id, llm_verify_image_prompt, llm_verify_image_response_json, llm_verify_image_text, image_verified\n",
    "          FROM `{dataset_id}.customer_hyper_personalised_email`\n",
    "         WHERE customer_id IN ({customer_ids_formatted})\n",
    "           AND email_date = CURRENT_DATE()\"\"\"\n",
    "\n",
    "print(sql)\n",
    "df_process = RunQuery(sql)\n",
    "df_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OabA8ZAhC5IX"
   },
   "source": [
    "### <font color='#4285f4'>Translate the Marketing Message to another language</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xYdA9VKDIQV"
   },
   "outputs": [],
   "source": [
    "# Translate the marketing text into another language (we will randomly pick on)\n",
    "\n",
    "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
    "# Make all fields required.\n",
    "#  {\n",
    "#    \"translated_text\" : \"text\"\n",
    "#  }\n",
    "response_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"required\": [\n",
    "    \"translated_text\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"translated_text\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "for item in customer_list:\n",
    "  # Pick an random language from the list\n",
    "  random_language = 12 # we will do German or you can do a Random language: random.randint(0,len(gemini_languages)-1)\n",
    "  print(f\"Random Language: {gemini_languages[random_language]}\")\n",
    "  print(f\"Customer id: {item['customer_id']}\")\n",
    "  item['translation_language'] = gemini_languages[random_language]\n",
    "  try:\n",
    "\n",
    "    prompt = f\"\"\"You are an expert translator for the following language {gemini_languages[random_language]}.\n",
    "    Translate the following text from English to {gemini_languages[random_language]}:\n",
    "    <Text>\n",
    "    {item['marketing_text']}\n",
    "    </Text>\n",
    "    \"\"\"\n",
    "\n",
    "    print(prompt)\n",
    "    llm_result = GeminiLLM(prompt, response_schema=response_schema)\n",
    "    print(llm_result)\n",
    "    json_result = json.loads(llm_result)\n",
    "    result_escaped_quotes = llm_result.replace(\"\\\\\",\"\\\\\\\\\").replace(\"'\",\"\\'\")\n",
    "\n",
    "    # Update table in BigQuery\n",
    "    try:\n",
    "      sql=f\"\"\"UPDATE `{dataset_id}.customer_hyper_personalised_email`\n",
    "                  SET llm_translation_language_prompt = \\\"\\\"\\\"{prompt}\\\"\\\"\\\",\n",
    "                      llm_translation_language_prompt_response_json = JSON\\\"\\\"\\\"{result_escaped_quotes}\\\"\\\"\\\",\n",
    "                      llm_translation_language_prompt_response_text = \\\"\\\"\\\"{json_result['translated_text']}\\\"\\\"\\\"\n",
    "                WHERE customer_id = '{item['customer_id']}'\"\"\"\n",
    "\n",
    "      #print(sql)\n",
    "      RunQuery(sql)\n",
    "      item['translated_text'] = json_result['translated_text']\n",
    "\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "      print(f\"Translation [Success] for Customer {item['customer_id']}\")\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "    except Exception as e:\n",
    "      retry += 1\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "      print(f\"Translation [SQL Error] for Customer {item['customer_id']}: {sql}\")\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n",
    "    print(f\"Translation [Error] for Customer {item['customer_id']}: {e}\")\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_7QtxRWnP0Ll"
   },
   "outputs": [],
   "source": [
    "# View Results\n",
    "sql=f\"\"\"SELECT customer_id, llm_translation_language_prompt, llm_translation_language_prompt_response_json, llm_translation_language_prompt_response_text\n",
    "          FROM `{dataset_id}.customer_hyper_personalised_email`\n",
    "         WHERE customer_id IN ({customer_ids_formatted})\n",
    "           AND email_date = CURRENT_DATE()\"\"\"\n",
    "\n",
    "print(sql)\n",
    "df_process = RunQuery(sql)\n",
    "df_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrS2IH6VC9l-"
   },
   "source": [
    "### <font color='#4285f4'>Verify the Translation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I1p7flicDItv"
   },
   "outputs": [],
   "source": [
    "# Verify the translation is correct\n",
    "\n",
    "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
    "# Make all fields required.\n",
    "#  {\n",
    "#    \"translation_verified\" : true\n",
    "#    \"explanation\" : \"text\"\n",
    "#  }\n",
    "response_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"required\": [\n",
    "    \"translation_verified\",\n",
    "    \"explanation\"\n",
    "  ],\n",
    "  \"properties\": {\n",
    "    \"translation_verified\": {\n",
    "      \"type\": \"boolean\"\n",
    "    },\n",
    "    \"explanation\": {\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "for item in customer_list:\n",
    "  print(f\"Customer id: {item['customer_id']}\")\n",
    "  try:\n",
    "    prompt = f\"\"\"I need you to verify that the below text is in the langugage of \"{item['translation_language']}\".\n",
    "    It was originially in English, so make sure it is not still English.\n",
    "    <Text>\n",
    "    {item['translated_text']}\n",
    "    </Text>\n",
    "    \"\"\"\n",
    "\n",
    "    print(prompt)\n",
    "    llm_result = GeminiLLM(prompt, response_schema=response_schema)\n",
    "    print(llm_result)\n",
    "    json_result = json.loads(llm_result)\n",
    "    result_escaped_quotes = llm_result.replace(\"\\\\\",\"\\\\\\\\\").replace(\"'\",\"\\'\")\n",
    "\n",
    "    # Update table in BigQuery\n",
    "    try:\n",
    "      sql=f\"\"\"UPDATE `{dataset_id}.customer_hyper_personalised_email`\n",
    "                  SET llm_validate_translation_prompt = \\\"\\\"\\\"{prompt}\\\"\\\"\\\",\n",
    "                      llm_validate_translation_prompt_response_json = JSON\\\"\\\"\\\"{result_escaped_quotes}\\\"\\\"\\\",\n",
    "                      llm_validate_translation_prompt_response_text = \\\"\\\"\\\"{json_result['explanation']}\\\"\\\"\\\",\n",
    "                      translation_verified = {json_result['translation_verified']}\n",
    "                WHERE customer_id = '{item['customer_id']}'\"\"\"\n",
    "\n",
    "      #print(sql)\n",
    "      RunQuery(sql)\n",
    "\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "      print(f\"Translation Verification [Success] for Customer {item['customer_id']}\")\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "    except Exception as e:\n",
    "      retry += 1\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "      print(f\"Translation Verification [SQL Error] for Customer {item['customer_id']}: {sql}\")\n",
    "      print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n",
    "    print(f\"Translation Verification [Error] for Customer {item['customer_id']}: {e}\")\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNQoVMarRGxl"
   },
   "outputs": [],
   "source": [
    "# View Results\n",
    "sql=f\"\"\"SELECT customer_id, llm_validate_translation_prompt, llm_validate_translation_prompt_response_json, llm_validate_translation_prompt_response_text, translation_verified\n",
    "          FROM `{dataset_id}.customer_hyper_personalised_email`\n",
    "         WHERE customer_id IN ({customer_ids_formatted})\n",
    "           AND email_date = CURRENT_DATE()\"\"\"\n",
    "\n",
    "print(sql)\n",
    "df_process = RunQuery(sql)\n",
    "df_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sCUluQyDB6-"
   },
   "source": [
    "### <font color='#4285f4'>Generate the HTML and Save</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xT1UZX2rDJNv"
   },
   "outputs": [],
   "source": [
    "html_template = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "  <title>Insurance upgrade Campaign</title>\n",
    "  <style>\n",
    "    body {\n",
    "      font-family: 'Helvetica Neue', sans-serif;\n",
    "    }\n",
    "    .email-campaign {\n",
    "      background-color: #EDF2F9;\n",
    "      padding: 20px;\n",
    "      margin-bottom: 20px;\n",
    "      border-bottom: 2px solid #ddd;\n",
    "    }\n",
    "    h3 {\n",
    "      font-size: 16px;\n",
    "      margin-bottom: 10px;\n",
    "      color: #333;\n",
    "    }\n",
    "    p {\n",
    "      font-size: 14px;\n",
    "      line-height: 1.5;\n",
    "      color: #555;\n",
    "    }\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <div class=\"email-campaign\">\n",
    "    <h3>Email Campaign (English)</h3>\n",
    "    <p style=\"font-weight: bold;\">Subject: ##email_subject##</p>\n",
    "    <p>##marketing_text##</p>\n",
    "  </div>\n",
    "  <div>\n",
    "    <img src=\"##html_filename##\" width=\"500\" height=\"500\" alt=\"Item Image\">\n",
    "  </div>\n",
    "\n",
    "  <hr/>\n",
    "\n",
    "  <div class=\"email-campaign\">\n",
    "    <h3>Email Campaign (##translation_language##)</h3>\n",
    "    <p>##translated_text##</p>\n",
    "  </div>\n",
    "  <div>\n",
    "    <img src=\"##html_filename##\" width=\"500\" height=\"500\" alt=\"Item Image\">\n",
    "  </div>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7ApKaWhSdHE"
   },
   "outputs": [],
   "source": [
    "# Create HTML using the Template\n",
    "\n",
    "for item in customer_list:\n",
    "  print(item)\n",
    "  if 'html_filename' not in item:\n",
    "    # Error generating image\n",
    "    print(\"Error: 'html_filename' not in item\")\n",
    "    continue\n",
    "\n",
    "  if 'translated_text' not in item:\n",
    "    # Error generating translation\n",
    "    print(\"Error: 'translated_text' not in item\")\n",
    "    continue\n",
    "\n",
    "  # Replace the placeholders with the actual values\n",
    "  html = html_template \\\n",
    "    .replace(\"##email_subject##\", item['email_subject']) \\\n",
    "    .replace(\"##marketing_text##\", item['marketing_text']) \\\n",
    "    .replace(\"##translation_language##\", item['translation_language']) \\\n",
    "    .replace(\"##translated_text##\", item['translated_text']) \\\n",
    "    .replace(\"##html_filename##\", item['html_filename'])\n",
    "\n",
    "  filename = f\"email_campaign_{item['customer_id']}.html\"\n",
    "\n",
    "  # Save the HTML to a file\n",
    "  with open(filename, \"w\") as f:\n",
    "    f.write(html)\n",
    "\n",
    "  copy_file_to_gcs(filename, storage_account,f\"insurance-data/Campaign-Assets-Hyper-Personalised-Email/email-{formatted_date}/\" + filename)\n",
    "\n",
    "  # Update table in BigQuery\n",
    "  try:\n",
    "    html_gcs_filename = f\"gs://{storage_account}/insurance-data/Campaign-Assets-Hyper-Personalised-Email/email-{formatted_date}/{filename}\"\n",
    "    html_http_url = f\"https://storage.cloud.google.com/{storage_account}/insurance-data/Campaign-Assets-Hyper-Personalised-Email/email-{formatted_date}/{filename}\"\n",
    "\n",
    "    sql=f\"\"\"UPDATE `{dataset_id}.customer_hyper_personalised_email`\n",
    "                SET html_gcs_filename = '{html_gcs_filename}',\n",
    "                    html_http_url = '{html_http_url}',\n",
    "                    html_generated = TRUE\n",
    "              WHERE customer_id = '{item['customer_id']}'\"\"\"\n",
    "\n",
    "    #print(sql)\n",
    "    RunQuery(sql)\n",
    "\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n",
    "    print(f\"HTML Generation [Success] for Customer {item['customer_id']}\")\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n",
    "\n",
    "  except Exception as e:\n",
    "    retry += 1\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n",
    "    print(f\"HTML Generation [SQL Error] for Customer {item['customer_id']}: {sql}\")\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAPgeLTndZTF"
   },
   "outputs": [],
   "source": [
    "# To view the bucket\n",
    "print(f\"https://console.cloud.google.com/storage/browser/{storage_account}/insurance-data/Campaign-Assets-Hyper-Personalised-Email/email-{formatted_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VThvmO_SZmF5"
   },
   "outputs": [],
   "source": [
    "# View Results\n",
    "sql=f\"\"\"SELECT customer_id, html_gcs_filename, html_http_url, html_generated\n",
    "          FROM `{dataset_id}.customer_hyper_personalised_email`\n",
    "         WHERE customer_id IN ({customer_ids_formatted})\n",
    "           AND email_date = CURRENT_DATE();\"\"\"\n",
    "\n",
    "print(sql)\n",
    "df_process = RunQuery(sql)\n",
    "df_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WT3u1L_aVayT"
   },
   "outputs": [],
   "source": [
    "filename = f\"email_campaign_{customer_list[7]['customer_id']}.html\"\n",
    "IPython.display.HTML(filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcRVFkNIXNT1"
   },
   "outputs": [],
   "source": [
    "filename = f\"email_campaign_{customer_list[9]['customer_id']}.html\"\n",
    "IPython.display.HTML(filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfLXgbircpZk"
   },
   "source": [
    "### <font color='#4285f4'>View all results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31W7KOUzZs4g"
   },
   "outputs": [],
   "source": [
    "# View All Results\n",
    "sql=f\"\"\"SELECT *\n",
    "          FROM `{dataset_id}.customer_hyper_personalised_email`\n",
    "         WHERE customer_id IN ({customer_ids_formatted})\n",
    "           AND email_date = CURRENT_DATE();\"\"\"\n",
    "\n",
    "print(sql)\n",
    "df_process = RunQuery(sql)\n",
    "df_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42IxhtRRrvR-"
   },
   "source": [
    "### <font color='#4285f4'>Clean Up</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lF2Z7skFbvf"
   },
   "outputs": [],
   "source": [
    "# Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASQ2BPisXDA0"
   },
   "source": [
    "### <font color='#4285f4'>Reference Links</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTY6xJdZ3ul8"
   },
   "source": [
    "- [Imagen3](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/image-generation)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "HMsUvoF4BP7Y",
    "m65vp54BUFRi",
    "UmyL-Rg4Dr_f",
    "JbOjdSP1kN9T",
    "EYRHDPdVKBzd",
    "HNZanAdJEaPq",
    "oMl8zBaOEfy8",
    "xPM7R0UdU7Q4",
    "c51M89g0Ejmz",
    "SLK7IX7QruT3",
    "2olP2ZnglJlr",
    "ASQ2BPisXDA0"
   ],
   "name": "Campaign-Assets-Hyper-Personalized-Email",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
